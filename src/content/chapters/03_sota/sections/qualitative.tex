\section{Qualitative Analysis\label{sec:sota.quali}}

This section contains the results of our literature review.
First, it synthesizes the analyses into a reference architecture and a taxonomy for \glspl{fids}, which help structure the field.
Then, it goes over a comparison of the selected works to answer \Cref{rq:sota.components} on the components of \glspl{fids} and their impact on performance.


\subsection{Structuring the Literature\label{sec:sota.quali.structure}}

The qualitative (\Cref{sec:sota.quali}) and quantitative (\Cref{sec:sota.quanti}) analyzes provide results that we synthesize hereafter in a reference architecture and a taxonomy.
The reference architecture presents the components of \glspl{fids} and their interactions, while the taxonomy provides comparison criteria for the selected works.

We build the taxonomy upon different existing ones related to \gls{cids}
\cite{vasilomanolakis_TaxonomySurveyCollaborative_2015,zhou_surveycoordinatedattacks_2010}, \gls{ml}--based intrusion detection~\cite{dacosta_InternetThingssurvey_2019}, and
\gls{fl} \cite{aledhari_FederatedLearningSurvey_2020,lyu_ThreatsFederatedLearning_2020,mothukuri_surveysecurityprivacy_2021}.
First, we extract classes relevant to the domain
of \gls{fids}, before filtering out irrelevant ones by validating the taxonomy against the reference architecture (\Cref{fig:sota.archi}).
The latter displays both the operation and
the design of the system.
By confronting the taxonomy and the architecture, we ensure that each item
of the taxonomy is related to a component of the architecture, and \emph{vice versa}.
Then, we add any commonalities between the selected works that are not already represented in the previous taxonomies.
This identifies new criteria on which to compare the selected works.


\subsubsection{Reference Architecture\label{sec:sota.discuss.synthesis.archi}}

\begin{figure*}
  \centering
  \includegraphics[width=.95\textwidth]{figures/architecture.drawio.pdf}
  \caption{The proposed reference architecture for \glspl{fids}---Figure from \textcite{lavaur_EvolutionFederatedLearningbased_2022} \copyright~IEEE 2022.}
  \label{fig:sota.archi}
\end{figure*}

This section presents the reference architecture synthesized from the selected works, as depicted in \Cref{fig:sota.archi}.
It can be divided in three parts:
\begin{itemize}
  \item The \emph{Managed system} represents the monitored system, \eg, \gls{it} network, industrial devices, or health-monitoring wearables.
  As noticed in \Cref{sec:sota.quali.data}, collected data can either concern system or environment behavior.
  The former relates to information generated by the systems, \eg, network traces or resource consumption.
  The latter refers to what the monitored system operates on, \eg, health metrics for medical devices of temperature and atmospheric pressure for building management systems.
  
  \item The \emph{Security subsystem} is the core of the architecture.
  It contains all the system's activities, from model training to detection and counter-measures deployment.
  Depending on the objectives and constraints, this subsystem can either be run locally like \cite{pahl_AllEyesYou_2018} or \cite{hei_trustedfeatureaggregator_2020}, on a dedicated edge-device as in \cite{li_DeepFedFederatedDeep_2020}.
  In the case of centralized learning, this entire subsystem runs in the cloud.
  The subsystem is assumed to run a device that embeds enough computing power to perform real-time anomaly detection against \gls{ml} models.
  It is also capable of training its own model based on collected data.

  \item The \emph{Collaboration subsystem} provides the \emph{sharing} feature of the system, essentially model aggregation (\Cref{sec:sota.quali.agg}).
  It also provides optional training from other sources, like online datasets.
\end{itemize}

This architecture has similarities with the principles of autonomic systems, as defined by IBM in 2001~\cite{kephart_visionautonomiccomputing_2003}, referred to as \gls{mape-k}.
Classic autonomic systems are local, and therefore use a database to provide \emph{knowledge}.
In \gls{fids}, \gls{fl} fills this role in the reference architecture, as the knowledge is being shared among all agents through model aggregation.


\subsubsection{Taxonomy for FIDS\label{sec:sota.discuss.synthesis.taxo}}

The taxonomy depicted in \Cref{fig:sota.taxonomy} summaries the core components and specificities of \glspl{fids}, as extracted from the selected works and existing related taxonomies.
Correlations between the taxonomy items and the system's components can be seen in the reference architecture (\Cref{fig:sota.archi}).
It also serves as a framework for the comparisons of the selected works.
Each class represents a building block, for which multiple approaches exist depending on use case and constraints.

\begin{figure}
  \centering
  \resizebox{\textwidth}{!}{\input{figures/taxonomy.tikz.tex}}
  \caption{
    Proposed taxonomy for FIDS---Figure from \textcite{lavaur_EvolutionFederatedLearningbased_2022} \copyright~IEEE 2022.
    \label{fig:sota.taxonomy}
  }
\end{figure}


The proposed taxonomy contains 12 classes describing the selected works that span over five main aspects:
\begin{itemize}
  \item Two classes cover the topic of \textbf{Data}: \emph{Data source \& type} and \emph{Preprocessing}.
  It defines the type of data considered, how it is collected, and the preprocessing strategies that are used.
  
  \item \textbf{Local operation} is represented by 3 classes: \emph{ML location}, \emph{Local algorithms}, and \emph{Defense capabilities}.
  It describes the detection and mitigation strategies, how models are built and trained, and where the computing resources are located.
  
  \item The \textbf{Federation} aspect is covered by 2 classes: \emph{Federation strategy} and \emph{Communication}.
  They refer to the communication between the agents and the server, and how data sharing is organized.
  
  \item \textbf{Aggregation} is also covered by 3 classes: \emph{FL type}, \emph{Aggregation strategy}, and \emph{Model target}.
  It describes the type of \gls{fl} used, how the models are merged, in accordance with the objectives of the system.
  
  \item Finally, 2 classes define the \textbf{Experimentation} topic: \emph{Analyzed dataset} and \emph{Costs and metrics}.
  This meta-category does not relate to the proposed solution, but to how the experiments are performed.
\end{itemize}



\subsection{Federated Learning for Intrusion Detection\label{sec:sota.quali.fids}}

This section reviews the selected literature.
Using the taxonomy as a reference, it details and compares the selected works.
\Cref{tbl:sota.comp} summarizes the information and helps identify differences between the works.
It gives partial answers to research questions about the components of \glspl{fids} and how to measure their impact on performance (\Cref{rq:sota.components,rq:sota.metrics}), while \Cref{sec:sota.quali.agg} replies to \Cref{rq:sota.techniques} about federation techniques.


\begin{table}[]
  \centering
  \caption{
    Comparative overview of selected works---approach and objectives (1/2)
    \label{tbl:sota.comp}
  }
  \resizebox{\textwidth}{!}{\input{figures/table-comp.tex}}
\end{table}

\begin{table}[]
  \centering
  \caption{
    Comparative overview of selected works---algorithms and performance (2/2)
    \label{tbl:selected.perf}
  }
  \resizebox{\textwidth}{!}{\input{figures/table-perf.tex}}
\end{table}

\subsubsection{Data Source and Type\label{sec:sota.quali.data}}

Depending on the use case, we observe two main approaches in the selected works.
In the first one~\cite{zhang_BlockchainbasedFederatedLearning_2020,schneble_Attackdetectionusing_2019}, the model is trained on the sensors' values.
While they are not represented in the initial selection, this is closer to \glspl{hids} in operation.
For instance, since~\cite{zhang_BlockchainbasedFederatedLearning_2020} targets medical devices, their values include hearth rate and oxygen saturation.
The opposite strategy operates at a higher level of abstraction, independent of the values, and rather focuses on the communication between devices using network traffic, just like \glspl{nids}.
Most papers \cite{chen_Networkanomalydetection_2020,rathore_BlockSecIoTNetBlockchainbaseddecentralized_2019,nguyen_DIoTFederatedSelflearning_2019,li_DeepFedFederatedDeep_2020,rahman_InternetThingsIntrusion_2020,sun_IntrusionDetectionSegmented_2020,popoola_FederatedDeepLearning_2021a,hei_trustedfeatureaggregator_2020} use similar network features, such as source and destination, local and remote ports, TCP flags, protocol, and packet length.
The authors of \cite{qin_LineSpeedScalableIntrusion_2020a} also target network features but at packet-level, all translated to 1D vectors: IP addresses, layer-4 protocol, ports, and IP packet length as a 120-bit input vector.
\textcite{li_DeepFedFederatedDeep_2020} also explore network-related features in their use case of satellite communications.

These values can be completed with preprocessing (see \Cref{sec:sota.quali.preprocess}) to extract other features from the raw data.
For instance, both \textcite{pahl_AllEyesYou_2018} and \textcite{nguyen_DIoTFederatedSelflearning_2019} analyze the periodicity of packets, which is notably useful for volumetric attack detection.
Furthermore, both work target \gls{iot} devices, which have a sporadic, but periodic and thus more predicable traffic.
In this context, anomaly in the packet-sequence, or in the inter-arrival time might indicate an attack.
While following a similar approach, \gls{ftl} allows the authors of \cite{fan_IoTDefenderFederatedTransfer_2020} to address different features in each client's dataset.

Finally, using a middleware to classify the data, \textcite{pahl_AllEyesYou_2018} can train per-class models with high accuracy.
However, most solutions do not provide such metadata.
Training per-class models requires then a prior classification step, like in \cite{nguyen_DIoTFederatedSelflearning_2019}.

Additionally, even when considering the same data type, use cases introduce significant differences in the available features.
For instance, two systems targeting the communication between devices may encounter different protocols, services, and even communication support.
In the literature, the most common use cases are (sorted by representation): \acrfull{it}, \acrfull{iot}, \acrfull{cps}, and \acrfull{av}.

% The work of \textcite{liu_BlockchainFederatedLearning_2021} is the only representative of the \gls{av} use case, although they do not use an according dataset.
% In fact, they train their model on network traffic, with similar features to \cite{rahman_InternetThingsIntrusion_2020,chen_Networkanomalydetection_2020,rathore_BlockSecIoTNetBlockchainbaseddecentralized_2019,fan_IoTDefenderFederatedTransfer_2020}.
% With also similar features, \textcite{li_DeepFedFederatedDeep_2020b} apply \gls{fids} to the very specific use case of \gls{stin}.

Finally, \cite{chen_Networkanomalydetection_2020}, and partly  \cite{hei_trustedfeatureaggregator_2020}, address data distribution, especially knowing whether data are \gls{iid}.
A non-\gls{iid} data distribution can negatively impact training performance~\cite{Yang2019}.
However, most real-world scenarios generate non-\gls{iid} data, which is a major hurdle for algorithm that require to be trained on live data with non-supervised approaches.

\subsubsection{Preprocessing\label{sec:sota.quali.preprocess}}

\subsubsection{Algorithm location\label{sec:sota.quali.location}}

\subsubsection{Local Algorithm\label{sec:sota.quali.alg}}

\subsubsection{Defense Mechanism\label{sec:sota.quali.defense}}

\subsubsection{Federation Strategy\label{sec:sota.quali.fed}}

\subsubsection{Communication\label{sec:sota.quali.comm}}

\subsubsection{FL Type\label{sec:sota.quali.type}}

\subsubsection{Aggregation Strategy\label{sec:sota.quali.agg}}

\subsubsection{Model Target\label{sec:sota.quali.target}}

\subsubsection{Analysed Dataset\label{sec:sota.quali.dataset}}

\subsubsection{Costs and Metrics\label{sec:sota.quali.metrics}}
